{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install langgraph\n",
        "!pip install pydantic\n",
        "!pip install openai\n",
        "!pip install langchain\n",
        "!pip install langchain_openai"
      ],
      "metadata": {
        "collapsed": true,
        "id": "tNOqHVZPiX6k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import asyncio\n",
        "import os\n",
        "from typing import Dict, List, Optional, Any, TypedDict, Annotated\n",
        "from datetime import date\n",
        "from pydantic import BaseModel, Field\n",
        "from openai import AsyncOpenAI\n",
        "from langgraph.graph import StateGraph, END\n",
        "import json\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "os.environ[\"OPENROUTER_API_KEY\"] = \"your-openrouterkey\"\n",
        "os.environ[\"OPENROUTER_BASE_URL\"] = \"https://openrouter.ai/api/v1\"\n",
        "\n",
        "llm = ChatOpenAI(\n",
        "    model=\"openai/gpt-4.1-mini\",\n",
        "    openai_api_base=os.getenv(\"OPENROUTER_BASE_URL\"),\n",
        "    openai_api_key=os.getenv(\"OPENROUTER_API_KEY\"),\n",
        "    temperature=0.3\n",
        ")\n",
        "\n",
        "TODAY_DATE = date.today().strftime(\"%Y-%m-%d\")\n",
        "\n",
        "class ResearchTask(BaseModel):\n",
        "    task_name: str = Field(description=\"SPECIFIC name for this research task\")\n",
        "    objective: str = Field(description=\"Clear statement focused on a SPECIFIC aspect of the research\")\n",
        "    search_terms: List[str] = Field(description=\"5 HIGHLY SPECIFIC search terms\")\n",
        "    output_format: str = Field(description=\"Specify the required format: table, bullet points, etc.\")\n",
        "    required_data_points: List[str] = Field(description=\"List 5-7 SPECIFIC data points to collect\")\n",
        "    template: str = Field(description=\"Provide a detailed template with placeholders\")\n",
        "    date_range: Optional[str] = Field(default=None, description=\"Optional date range for the research\")\n",
        "\n",
        "class ResearchTaskSet(BaseModel):\n",
        "    purpose: str = Field(description=\"Clear, concise statement focused EXACTLY on the user's research request\")\n",
        "    tasks: List[ResearchTask] = Field(description=\"List of specific research tasks\")\n",
        "\n",
        "class TopicAnalysis(BaseModel):\n",
        "    research_type: str = Field(description=\"Classification of research type: company_analysis, market_research, investment_opportunities, general\")\n",
        "    industry: str = Field(default=\"\", description=\"Industry or sector of focus\")\n",
        "    primary_focus: str = Field(description=\"Primary focus of the research\")\n",
        "    estimated_entity_count: int = Field(default=5, description=\"Estimated number of entities to research\")\n",
        "    recommended_task_count: int = Field(default=5, description=\"Recommended number of research tasks (3-5)\")\n",
        "    time_frame: str = Field(default=\"current\", description=\"Time frame relevance\")\n",
        "    template_keys: List[str] = Field(description=\"Most relevant template keys from available templates\")\n",
        "\n",
        "class SearchResult(BaseModel):\n",
        "    query: str\n",
        "    result: str\n",
        "    sources: List[str] = []\n",
        "\n",
        "class ResearchState(TypedDict):\n",
        "    user_query: str\n",
        "    topic_analysis: Optional[Dict[str, Any]]\n",
        "    research_tasks: List[Dict[str, Any]]\n",
        "    search_results: List[Dict[str, Any]]\n",
        "    final_article: str\n",
        "    status: str\n",
        "\n",
        "TEMPLATES = {\n",
        "    \"investment_thesis\": \"\"\"\n",
        "    COMPANY INVESTMENT PROFILE - Data Points to Collect:\n",
        "\n",
        "    Financial Metrics:\n",
        "    - Current market cap, enterprise value, share price\n",
        "    - Revenue (TTM), revenue growth (1Y, 3Y CAGR)\n",
        "    - Gross margin, EBITDA margin, net margin percentages\n",
        "    - Free cash flow generation and cash conversion cycle\n",
        "    - Debt-to-equity ratio, net cash position\n",
        "\n",
        "    Valuation Multiples:\n",
        "    - P/E ratio, EV/Revenue, EV/EBITDA (current and forward)\n",
        "    - PEG ratio and price-to-book value\n",
        "    - Dividend yield and payout ratio\n",
        "\n",
        "    Business Fundamentals:\n",
        "    - Primary revenue streams and business model\n",
        "    - Market share in core segments\n",
        "    - Customer concentration (top 10 customers as % of revenue)\n",
        "    - Geographic revenue breakdown\n",
        "    - Recurring revenue percentage\n",
        "\n",
        "    Recent Developments:\n",
        "    - Latest quarterly earnings results and guidance\n",
        "    - Recent analyst upgrades/downgrades and price targets\n",
        "    - Management changes and strategic initiatives\n",
        "    - Upcoming catalysts (product launches, regulatory decisions)\n",
        "    \"\"\",\n",
        "\n",
        "    \"market_intelligence\": \"\"\"\n",
        "    SECTOR & MARKET ANALYSIS - Data Points to Collect:\n",
        "\n",
        "    Market Size & Growth:\n",
        "    - Total addressable market (TAM) size and growth rate\n",
        "    - Market segments and fastest-growing subsectors\n",
        "    - Geographic market distribution and emerging regions\n",
        "\n",
        "    Industry Performance:\n",
        "    - Sector stock performance (YTD, 1Y, 3Y)\n",
        "    - Average sector valuation multiples vs historical ranges\n",
        "    - Top 5 companies by market cap and their market shares\n",
        "    - Recent IPOs and their post-listing performance\n",
        "\n",
        "    Capital Flows:\n",
        "    - Total VC/PE investment volume in sector (YTD vs prior year)\n",
        "    - Number and value of M&A transactions (last 12 months)\n",
        "    - Average deal multiples for recent transactions\n",
        "    - Major fundraising rounds and valuations\n",
        "\n",
        "    Regulatory & Trends:\n",
        "    - Recent regulatory changes or proposed legislation\n",
        "    - Government spending or policy support for sector\n",
        "    - Key technology trends disrupting the industry\n",
        "    - ESG considerations and climate-related impacts\n",
        "    \"\"\",\n",
        "\n",
        "    \"deal_sourcing\": \"\"\"\n",
        "    PRIVATE MARKET OPPORTUNITIES - Data Points to Collect:\n",
        "\n",
        "    Target Company Profile:\n",
        "    - Annual revenue, revenue growth rate (3Y CAGR)\n",
        "    - EBITDA margin and cash flow generation\n",
        "    - Employee count and geographic footprint\n",
        "    - Founded date and current ownership structure\n",
        "    - Key products/services and customer base\n",
        "\n",
        "    Investment Metrics:\n",
        "    - Current valuation or last funding round details\n",
        "    - Comparable public company trading multiples\n",
        "    - Recent private market transaction multiples in sector\n",
        "    - Average deal multiples for recent transactions\n",
        "    - Management ownership percentage and rollover intentions\n",
        "\n",
        "    Growth Drivers:\n",
        "    - Addressable market size and company's current penetration\n",
        "    - Product pipeline and R&D spending\n",
        "    - Geographic expansion opportunities\n",
        "    - Potential add-on acquisition targets\n",
        "\n",
        "    Competitive Landscape:\n",
        "    - Main competitors and their recent valuations/exits\n",
        "    - Market share rankings and differentiation factors\n",
        "    - Recent competitor fundraising or strategic moves\n",
        "    - Barriers to entry and switching costs\n",
        "    \"\"\"\n",
        "}\n",
        "\n",
        "PLANNER_SYSTEM_PROMPT = \"\"\"\n",
        "You are a research planning expert responsible for creating HIGHLY SPECIFIC and IMPACTFUL research tasks.\n",
        "\n",
        "CRITICAL INSTRUCTIONS FOR CREATING IMPACTFUL RESEARCH TASKS:\n",
        "1. BE EXTREMELY LITERAL about what the user has requested - focus precisely on their stated needs\n",
        "2. CREATE SPECIFIC tasks that directly address the primary focus\n",
        "3. BREAK DOWN broad requests into concrete, actionable research objectives\n",
        "4. TARGET specific sub-categories rather than creating general overview tasks\n",
        "5. USE PRECISE search terms that will find specific information, not general trends\n",
        "6. REQUIRE CONCRETE data points that deliver actionable insights\n",
        "7. ENSURE all tasks align with the time frame\n",
        "8. VERY IMPORTANT: You don't give advice, you just look for information\n",
        "\n",
        "BEST PRACTISES:\n",
        "- To make research specific and useful, use sub-industries instead of main industry\n",
        "- Use 3-5 subindustries per task\n",
        "- Always add numbers in the search queries.\n",
        "    e.g: WRONG: Recent startups news in industry\n",
        "         CORRECT: 20 startups that 'some action' in 'sub industry'\n",
        "- Try understanding a hidden intention from the user query\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "WRITER_SYSTEM_PROMPT = \"\"\"\n",
        "You are an expert investment research writer. Create comprehensive, professional research articles.\n",
        "\n",
        "GUIDELINES:\n",
        "- Write in a professional, analytical tone\n",
        "- Include executive summary, detailed analysis, and conclusions\n",
        "- Cite sources and provide evidence for claims\n",
        "- Structure content logically with clear sections\n",
        "- Focus on investment implications and actionable insights\n",
        "- Length: 1500-2500 words\n",
        "\n",
        "Today's date: {today_date}\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "r5GybxWKpAIA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JKuEEaBVXAGC"
      },
      "outputs": [],
      "source": [
        "class PlannerAgent:\n",
        "    def __init__(self):\n",
        "        self.templates = TEMPLATES\n",
        "        self.today_date = TODAY_DATE\n",
        "        self.llm = llm\n",
        "\n",
        "    async def analyze_topic(self, topic: str) -> TopicAnalysis:\n",
        "        \"\"\"Analyze user topic to extract research parameters\"\"\"\n",
        "        analysis_prompt = f\"\"\"\n",
        "        Analyze this investment research request: \"{topic}\"\n",
        "\n",
        "        Classify the research type as one of:\n",
        "        - company_analysis: specific company research\n",
        "        - market_research: sector/market analysis\n",
        "        - investment_opportunities: finding investments\n",
        "        - general: other research\n",
        "\n",
        "        Extract:\n",
        "        - Industry/sector\n",
        "        - Primary focus\n",
        "        - Recommended number of research tasks 7\n",
        "        - Time frame relevance\n",
        "        - Most relevant template keys from: {list(self.templates.keys())}\n",
        "\n",
        "        Return the analysis in JSON format.\n",
        "        \"\"\"\n",
        "\n",
        "        try:\n",
        "            structured_llm = self.llm.with_structured_output(\n",
        "                TopicAnalysis,\n",
        "                method=\"function_calling\"\n",
        "            )\n",
        "            analysis_data = await structured_llm.ainvoke(analysis_prompt)\n",
        "            return analysis_data\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Warning: Topic analysis failed with structured output: {e}. Using fallback.\")\n",
        "            return TopicAnalysis(\n",
        "                research_type=\"general\",\n",
        "                industry=\"Investment\",\n",
        "                primary_focus=topic,\n",
        "                recommended_task_count=3,\n",
        "                template_keys=[\"market_intelligence\"]\n",
        "            )\n",
        "\n",
        "    async def create_research_tasks(self, topic: str, analysis: TopicAnalysis) -> ResearchTaskSet:\n",
        "        \"\"\"Generate specific research tasks based on analysis\"\"\"\n",
        "        template_examples = \"\\n\".join([\n",
        "            f\"Template {key}:\\n{content}\"\n",
        "            for key in analysis.template_keys\n",
        "            for content in [self.templates.get(key, \"\")]\n",
        "            if content\n",
        "        ])\n",
        "\n",
        "        planning_prompt = f\"\"\"\n",
        "        Create {analysis.recommended_task_count} research tasks for: \"{topic}\"\n",
        "\n",
        "        Research Focus: {analysis.primary_focus}\n",
        "        Industry: {analysis.industry}\n",
        "        Time Frame: {analysis.time_frame}\n",
        "\n",
        "        Template Examples:\n",
        "        {template_examples}\n",
        "\n",
        "        Each task should:\n",
        "        - Have a specific, focused objective\n",
        "        - Include 3-5 relevant search terms\n",
        "        - Specify output format\n",
        "        - List required data points\n",
        "        - Use appropriate template.\n",
        "\n",
        "        Return the tasks in JSON format.\n",
        "        \"\"\"\n",
        "\n",
        "        system_prompt = PLANNER_SYSTEM_PROMPT.format(\n",
        "            today_date=self.today_date,\n",
        "            templates=list(self.templates.keys())\n",
        "        )\n",
        "\n",
        "        try:\n",
        "            structured_llm = self.llm.with_structured_output(\n",
        "                ResearchTaskSet,\n",
        "                method=\"function_calling\"\n",
        "            )\n",
        "            tasks_data = await structured_llm.ainvoke(f\"{system_prompt}\\n\\n{planning_prompt}\")\n",
        "            return tasks_data\n",
        "        except Exception as e:\n",
        "            print(f\"Error generating research tasks with structured output: {e}\")\n",
        "            return ResearchTaskSet(\n",
        "                purpose=f\"Research tasks for {topic}\",\n",
        "                tasks=[\n",
        "                    ResearchTask(\n",
        "                        task_name=\"General Research\",\n",
        "                        objective=f\"Research information about {topic}\",\n",
        "                        search_terms=[topic, \"investment\", \"analysis\"],\n",
        "                        output_format=\"structured report\",\n",
        "                        required_data_points=[\"key metrics\", \"market data\", \"recent developments\"],\n",
        "                        template=\"basic_research\"\n",
        "                    )\n",
        "                ]\n",
        "            )\n",
        "\n",
        "class SearchAgent:\n",
        "    def __init__(self):\n",
        "        self.client = AsyncOpenAI(\n",
        "            base_url=os.getenv(\"OPENROUTER_BASE_URL\"),\n",
        "            api_key=os.getenv(\"OPENROUTER_API_KEY\"),\n",
        "        )\n",
        "\n",
        "    async def search_single_query(self, query: str) -> SearchResult:\n",
        "        \"\"\"Execute single search query with web access\"\"\"\n",
        "        try:\n",
        "            response = await self.client.chat.completions.create(\n",
        "                model=\"x-ai/grok-beta:online\",\n",
        "                messages=[\n",
        "                    {\"role\": \"system\", \"content\": f\"You are a research assistant with web access. Today is {TODAY_DATE}. Provide comprehensive, current information with sources.\"},\n",
        "                    {\"role\": \"user\", \"content\": query}\n",
        "                ],\n",
        "                extra_body={\n",
        "                    \"search_parameters\": {\n",
        "                        \"mode\": \"on\",\n",
        "                        \"temperature\": 0.2,\n",
        "                        \"return_citations\": True,\n",
        "                        \"plugins\": [{\"id\": \"web\"}]\n",
        "                    }\n",
        "                }\n",
        "            )\n",
        "\n",
        "            result_content = response.choices[0].message.content\n",
        "\n",
        "            sources = []\n",
        "            lines = result_content.split('\\n')\n",
        "            for line in lines:\n",
        "                if 'http' in line.lower() or 'source:' in line.lower():\n",
        "                    sources.append(line.strip())\n",
        "\n",
        "            return SearchResult(\n",
        "                query=query,\n",
        "                result=result_content,\n",
        "                sources=sources[:5]\n",
        "            )\n",
        "\n",
        "        except Exception as e:\n",
        "            return SearchResult(\n",
        "                query=query,\n",
        "                result=f\"Search failed: {str(e)}\",\n",
        "                sources=[]\n",
        "            )\n",
        "\n",
        "    async def execute_research_tasks(self, tasks: List[ResearchTask]) -> List[SearchResult]:\n",
        "        \"\"\"Execute all research tasks concurrently\"\"\"\n",
        "        search_queries = []\n",
        "\n",
        "        for task in tasks:\n",
        "            query = f\"\"\"\n",
        "            Research Topic: {task.task_name}\n",
        "            Objective: {task.objective}\n",
        "            Focus Areas: {', '.join(task.required_data_points)}\n",
        "            Search Terms: {', '.join(task.search_terms)}\n",
        "            Date Range: {task.date_range or 'Recent'}\n",
        "\n",
        "            Please provide detailed information covering all the required data points.\n",
        "            \"\"\"\n",
        "            search_queries.append(query)\n",
        "\n",
        "        search_tasks = [self.search_single_query(query) for query in search_queries]\n",
        "        results = await asyncio.gather(*search_tasks)\n",
        "\n",
        "        return results\n",
        "\n",
        "class WriterAgent:\n",
        "    def __init__(self):\n",
        "        self.client = AsyncOpenAI(\n",
        "            base_url=os.getenv(\"OPENROUTER_BASE_URL\"),\n",
        "            api_key=os.getenv(\"OPENROUTER_API_KEY\"),\n",
        "        )\n",
        "\n",
        "    async def generate_article(self, user_query: str, search_results: List[SearchResult]) -> str:\n",
        "        \"\"\"Generate comprehensive investment research article\"\"\"\n",
        "\n",
        "        research_content = \"\"\n",
        "        for i, result in enumerate(search_results, 1):\n",
        "            research_content += f\"\\n\\n--- Research Finding {i} ---\\n\"\n",
        "            research_content += f\"Query: {result.query}\\n\"\n",
        "            research_content += f\"Results: {result.result}\\n\"\n",
        "            if result.sources:\n",
        "                research_content += f\"Sources: {'; '.join(result.sources)}\\n\"\n",
        "\n",
        "        writing_prompt = f\"\"\"\n",
        "        Write a comprehensive investment research article answering this query: \"{user_query}\"\n",
        "\n",
        "        Research Data:\n",
        "        {research_content}\n",
        "\n",
        "        Article Requirements:\n",
        "        1. Executive Summary (2-3 paragraphs)\n",
        "        2. Market Analysis & Context\n",
        "        3. Key Findings & Insights\n",
        "        4. Investment Implications\n",
        "        5. Risk Assessment\n",
        "        6. Conclusions & Recommendations\n",
        "        7. Sources & References\n",
        "\n",
        "        Style: Professional, analytical, fact-based\n",
        "        Length: 1500-2500 words\n",
        "        Focus: Investment decision-making insights\n",
        "        \"\"\"\n",
        "\n",
        "        system_prompt = WRITER_SYSTEM_PROMPT.format(today_date=TODAY_DATE)\n",
        "\n",
        "        response = await self.client.chat.completions.create(\n",
        "            model=\"openai/gpt-4.1-mini\",\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": system_prompt},\n",
        "                {\"role\": \"user\", \"content\": writing_prompt}\n",
        "            ],\n",
        "            temperature=0.6,\n",
        "            max_tokens=4000\n",
        "        )\n",
        "\n",
        "        return response.choices[0].message.content\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "planner = PlannerAgent()\n",
        "searcher = SearchAgent()\n",
        "writer = WriterAgent()\n",
        "\n",
        "async def planner_node(state: ResearchState) -> ResearchState:\n",
        "    \"\"\"Planner node: Analyze topic and create research tasks\"\"\"\n",
        "    print(f\"üîç Planning research for: {state['user_query']}\")\n",
        "\n",
        "    try:\n",
        "        analysis = await planner.analyze_topic(state[\"user_query\"])\n",
        "\n",
        "        task_set = await planner.create_research_tasks(state[\"user_query\"], analysis)\n",
        "\n",
        "        state[\"topic_analysis\"] = analysis.model_dump() if analysis else None\n",
        "        state[\"research_tasks\"] = [task.model_dump() for task in task_set.tasks] if task_set and task_set.tasks else []\n",
        "        state[\"status\"] = \"planned\"\n",
        "\n",
        "        print(f\"‚úÖ Created {len(state['research_tasks'])} research tasks\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Planning failed: {str(e)}\")\n",
        "        state[\"topic_analysis\"] = {\"error\": str(e)}\n",
        "        state[\"research_tasks\"] = []\n",
        "        state[\"status\"] = \"planning_failed\"\n",
        "\n",
        "    return state\n",
        "\n",
        "async def searcher_node(state: ResearchState) -> ResearchState:\n",
        "    \"\"\"Searcher node: Execute research tasks and gather information\"\"\"\n",
        "    print(f\"üîé Executing {len(state['research_tasks'])} research tasks...\")\n",
        "\n",
        "    try:\n",
        "        research_tasks_models = [ResearchTask(**task_dict) for task_dict in state[\"research_tasks\"]]\n",
        "\n",
        "        search_results_models = await searcher.execute_research_tasks(research_tasks_models)\n",
        "\n",
        "        state[\"search_results\"] = [result_model.model_dump() for result_model in search_results_models]\n",
        "        state[\"status\"] = \"researched\"\n",
        "\n",
        "        print(f\"‚úÖ Completed research with {len(state['search_results'])} results\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Search failed: {str(e)}\")\n",
        "        state[\"search_results\"] = [{\"error\": str(e), \"query\": \"failed\", \"result\": \"\", \"sources\": []}]\n",
        "        state[\"status\"] = \"search_failed\"\n",
        "\n",
        "    return state\n",
        "\n",
        "async def writer_node(state: ResearchState) -> ResearchState:\n",
        "    \"\"\"Writer node: Generate final research article\"\"\"\n",
        "    print(\"üìù Generating comprehensive research article...\")\n",
        "\n",
        "    try:\n",
        "        search_results_models = [SearchResult(**result_dict) for result_dict in state[\"search_results\"]\n",
        "                               if \"error\" not in result_dict]\n",
        "\n",
        "        if search_results_models:\n",
        "            article = await writer.generate_article(\n",
        "                state[\"user_query\"],\n",
        "                search_results_models\n",
        "            )\n",
        "        else:\n",
        "            article = f\"# Research Report: {state['user_query']}\\n\\nResearch could not be completed due to technical issues. Please try again.\"\n",
        "\n",
        "        state[\"final_article\"] = article\n",
        "        state[\"status\"] = \"completed\"\n",
        "\n",
        "        print(\"‚úÖ Article generation completed\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Writing failed: {str(e)}\")\n",
        "        state[\"final_article\"] = f\"Article generation failed: {str(e)}\"\n",
        "        state[\"status\"] = \"writing_failed\"\n",
        "\n",
        "    return state\n",
        "\n",
        "workflow = StateGraph(ResearchState)\n",
        "workflow.add_node(\"planner\", planner_node)\n",
        "workflow.add_node(\"searcher\", searcher_node)\n",
        "workflow.add_node(\"writer\", writer_node)\n",
        "workflow.add_edge(\"planner\", \"searcher\")\n",
        "workflow.add_edge(\"searcher\", \"writer\")\n",
        "workflow.add_edge(\"writer\", END)\n",
        "workflow.set_entry_point(\"planner\")\n",
        "app = workflow.compile()"
      ],
      "metadata": {
        "id": "onBNsoD2pOgE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "async def research_investment_topic(query: str) -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Main function to execute the complete investment research workflow\n",
        "    Args:\n",
        "        query: Investment research question/topic\n",
        "    Returns:\n",
        "        Complete research results including final article\n",
        "    \"\"\"\n",
        "    print(f\"üöÄ Starting investment research: {query}\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    initial_state = ResearchState(\n",
        "        user_query=query,\n",
        "        topic_analysis=None,\n",
        "        research_tasks=[],\n",
        "        search_results=[],\n",
        "        final_article=\"\",\n",
        "        status=\"initialized\"\n",
        "    )\n",
        "\n",
        "    try:\n",
        "        final_state = await app.ainvoke(initial_state)\n",
        "\n",
        "        print(\"=\" * 60)\n",
        "        print(\"üéâ Research completed successfully!\")\n",
        "\n",
        "        return {\n",
        "            \"query\": query,\n",
        "            \"status\": final_state[\"status\"],\n",
        "            \"tasks_created\": len(final_state.get(\"research_tasks\", [])),\n",
        "            \"research_results\": len(final_state.get(\"search_results\", [])),\n",
        "            \"article\": final_state.get(\"final_article\", \"\"),\n",
        "            \"full_state\": final_state\n",
        "        }\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Research failed: {str(e)}\")\n",
        "        return {\n",
        "            \"query\": query,\n",
        "            \"status\": \"failed\",\n",
        "            \"error\": str(e),\n",
        "            \"article\": \"\"\n",
        "        }\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def display_research_summary(result: Dict[str, Any]):\n",
        "    \"\"\"Display a formatted summary of research results\"\"\"\n",
        "    print(\"üìä INVESTMENT RESEARCH SUMMARY\")\n",
        "    print(\"=\" * 50)\n",
        "    print(f\"Query: {result['query']}\")\n",
        "    print(f\"Status: {result['status']}\")\n",
        "\n",
        "    if result['status'] == 'completed':\n",
        "        print(f\"Research Tasks: {result.get('tasks_created', 'N/A')}\")\n",
        "        print(f\"Search Results: {result.get('research_results', 'N/A')}\")\n",
        "        print(f\"Article Length: {len(result.get('article', ''))} characters\")\n",
        "        print(\"\\n\" + \"=\" * 50)\n",
        "        print(\"üìÑ FINAL ARTICLE\")\n",
        "        print(\"=\" * 50)\n",
        "        print(result.get('article', ''))\n",
        "    else:\n",
        "        print(f\"Error: {result.get('error', 'Unknown error')}\")\n",
        "\n",
        "def save_article_to_file(result: Dict[str, Any], filename: Optional[str] = None):\n",
        "    \"\"\"Save the research article to a markdown file\"\"\"\n",
        "    if result['status'] != 'completed':\n",
        "        print(\"‚ùå Cannot save: Research not completed successfully\")\n",
        "        return\n",
        "\n",
        "    if not filename:\n",
        "        safe_query = \"\".join(c for c in result['query'] if c.isalnum() or c in (' ', '-', '_')).rstrip()\n",
        "        filename = f\"research_{safe_query.replace(' ', '_')[:50]}.md\"\n",
        "\n",
        "    try:\n",
        "        with open(filename, 'w', encoding='utf-8') as f:\n",
        "            f.write(f\"# Investment Research Report\\n\\n\")\n",
        "            f.write(f\"**Query:** {result['query']}\\n\\n\")\n",
        "            f.write(f\"**Generated:** {TODAY_DATE}\\n\\n\")\n",
        "            f.write(f\"**Research Tasks:** {result.get('tasks_created', 'N/A')}\\n\\n\")\n",
        "            f.write(\"---\\n\\n\")\n",
        "            f.write(result.get('article', ''))\n",
        "\n",
        "        print(f\"‚úÖ Article saved to: {filename}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Failed to save article: {str(e)}\")\n",
        "\n",
        "\n",
        "async def main():\n",
        "    \"\"\"Main execution function\"\"\"\n",
        "    result = await research_investment_topic(\"Find future unicorns in fintech\")\n",
        "    display_research_summary(result)\n",
        "    # save_article_to_file(result)\n",
        "    return result\n",
        "\n",
        "result = await main()"
      ],
      "metadata": {
        "id": "_zWYZZ-lpT1t"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}